{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97228ecb",
   "metadata": {},
   "source": [
    "# üìò Enhanced CV Processing System (Multi-Industry Support)\n",
    "\n",
    "# üîß Improved Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5aa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredWordDocumentLoader\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "import getpass\n",
    "\n",
    "# Enhanced configuration\n",
    "STORAGE_DIR = \"cv_storage\"\n",
    "EMAIL_REGEX = r\"^[\\w\\.-]+@[a-zA-Z\\d\\.-]+\\.[a-zA-Z]{2,}$\"\n",
    "os.makedirs(STORAGE_DIR, exist_ok=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408dce3",
   "metadata": {},
   "source": [
    "# ================== Core Functions =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5184357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_user_email() -> tuple[str, str]:\n",
    "    \"\"\"Get and validate email with storage directory creation\"\"\"\n",
    "    while True:\n",
    "        email = input(\"üìß Enter your email address: \").strip().lower()\n",
    "        if not re.match(EMAIL_REGEX, email):\n",
    "            print(\"‚ùå Invalid email format. Use name@domain.com\")\n",
    "            continue\n",
    "            \n",
    "        # Sanitize email for filesystem safety\n",
    "        safe_email = re.sub(r\"[^\\w\\.-]\", \"_\", email)\n",
    "        user_dir = os.path.join(STORAGE_DIR, safe_email)\n",
    "        \n",
    "        if os.path.exists(user_dir):\n",
    "            print(\"‚úÖ Existing profile found\")\n",
    "            return email, user_dir\n",
    "            \n",
    "        os.makedirs(user_dir, exist_ok=True)\n",
    "        return email, user_dir\n",
    "\n",
    "def upload_cv(user_dir: str) -> str:\n",
    "    \"\"\"Handle CV upload with comprehensive validation\"\"\"\n",
    "    while True:\n",
    "        file_path = input(\"üìÑ Enter CV path (.pdf/.docx): \").strip()\n",
    "        \n",
    "        if not os.path.isfile(file_path):\n",
    "            print(\"‚ùå File not found\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            if file_path.lower().endswith(\".pdf\"):\n",
    "                loader = PyPDFLoader(file_path)\n",
    "            elif file_path.lower().endswith(\".docx\"):\n",
    "                loader = UnstructuredWordDocumentLoader(file_path)\n",
    "            else:\n",
    "                print(\"‚ùå Unsupported format. Use PDF/DOCX\")\n",
    "                continue\n",
    "\n",
    "            documents = loader.load()\n",
    "            text = \"\\n\".join([doc.page_content for doc in documents])\n",
    "            \n",
    "            # Save original file\n",
    "            safe_filename = re.sub(r\"[^\\w\\.-]\", \"_\", os.path.basename(file_path))\n",
    "            save_path = os.path.join(user_dir, safe_filename)\n",
    "            Path(save_path).write_bytes(Path(file_path).read_bytes())\n",
    "            \n",
    "            print(f\"‚úÖ CV saved: {save_path}\")\n",
    "            return text\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"üö® Error processing file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a886376",
   "metadata": {},
   "source": [
    "# ================== AI Processing Setup =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c32adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ProfessionalProfile(BaseModel):\n",
    "    \"\"\"Universal professional profile model\"\"\"\n",
    "    full_name: str = Field(..., description=\"Full legal name\")\n",
    "    contact_email: str = Field(..., description=\"Primary contact email\")\n",
    "    phone: Optional[str] = Field(None, description=\"Contact phone number\")\n",
    "    summary: Optional[str] = Field(None, description=\"Professional summary\")\n",
    "    \n",
    "    education: List[Dict] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of educational achievements with degrees, institutions, and dates\"\n",
    "    )\n",
    "    \n",
    "    experience: List[Dict] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Work history with job titles, companies, dates, and key achievements\"\n",
    "    )\n",
    "    \n",
    "    technical_skills: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Technical skills relevant to the industry\"\n",
    "    )\n",
    "    \n",
    "    certifications: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Professional certifications and licenses\"\n",
    "    )\n",
    "    \n",
    "    projects: List[Dict] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Notable projects with descriptions and outcomes\"\n",
    "    )\n",
    "    \n",
    "    industry_preferences: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Preferred industries or sectors\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270bbe8c",
   "metadata": {},
   "source": [
    "# Initialize AI components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d38e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = JsonOutputParser(pydantic_object=ProfessionalProfile)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"**Professional Profile Analysis Task**\n",
    "Act as an expert career analyst with deep knowledge across industries (tech, healthcare, finance, engineering). \n",
    "Extract structured information while identifying transferable skills and cross-domain competencies.\n",
    "\"Please extract the following fields from the CV and return them in JSON format without any preamble: ...\"\n",
    "\n",
    "**Fields to Extract:**\n",
    "- full_name\n",
    "- contact_email\n",
    "- phone\n",
    "- summary\n",
    "- linkedin\n",
    "- github\n",
    "- education (list)\n",
    "- experience (list)\n",
    "- technical_skills (list)\n",
    "- soft_skills (list, optional)\n",
    "- certifications (list)\n",
    "- projects (list)\n",
    "- languages (optional)\n",
    "YOU CAN ADD AND SUBTRACT FIELDS ACCORDING TO PROVIDED CV AND INDUSTRY\n",
    "\n",
    "**Analysis Guidelines:**\n",
    "1. Core Identification:\n",
    "- Extract full legal name from header/contact section\n",
    "- Verify email format (name@domain.tld)\n",
    "- Identify phone numbers in international format (+XXX...)\n",
    "- Extract summary\n",
    "- linked in link(if provided)\n",
    "- github link(if provided)\n",
    "\n",
    "2. Education Analysis:\n",
    "- Parse degrees with majors/specializations\n",
    "- Flag accreditation status for institutions\n",
    "- Convert dates to MM/YYYY format\n",
    "- Highlight research projects/theses\n",
    "\n",
    "\n",
    "3. Experience Processing:\n",
    "- Separate employment history from internships\n",
    "- Identify technical/soft skill development\n",
    "- Quantify achievements (\"Increased X by Y%\")\n",
    "- Map technologies to industry standards\n",
    "\n",
    "4. Skill Extraction:\n",
    "- Categorize skills:\n",
    "  ‚Ä¢ Technical (tools/platforms)\n",
    "  ‚Ä¢ Methodologies (Agile, Six Sigma)\n",
    "  ‚Ä¢ Domain Knowledge (HIPAA, GAAP)\n",
    "- Identify skill maturity levels:\n",
    "  (Beginner < 1yr, Intermediate 1-3yr, Expert 3+yr)\n",
    "\n",
    "5. Cross-Industry Transfer Analysis:\n",
    "- Identify portable competencies between industries\n",
    "- Highlight leadership/management patterns\n",
    "- Extract crisis management evidence\n",
    "- Flag multilingual capabilities\n",
    "\n",
    "**Structured Output Requirements:**\n",
    "{format_instructions}\n",
    "\n",
    "**Content Processing Rules:**\n",
    "- Preserve original wording unless ambiguous\n",
    "- Convert relative dates (\"current\" ‚Üí {today})\n",
    "- Expand acronyms first occurrence (WHO ‚Üí World Health Organization)\n",
    "- Handle conflicting info (prioritize most recent)\n",
    "- Omit sections not explicitly mentioned\n",
    "\n",
    "**Input Profile:**\n",
    "{text}\"\"\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "        \"today\": datetime.date.today().strftime(\"%m/%Y\")\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b33dcc",
   "metadata": {},
   "source": [
    "\n",
    "# Configure Groq LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7552e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API key: \")\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-8b-8192\",\n",
    "    temperature=0,\n",
    "    max_tokens=8192\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a233b3b7",
   "metadata": {},
   "source": [
    "\n",
    "# ================== Processing Functions ================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e1e98e-73b4-49ed-896a-b9d89ab221cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cv(text: str) -> dict:\n",
    "    \"\"\"Process CV text through LLM parsing chain\"\"\"\n",
    "    try:\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return dict(result)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error parsing CV: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "def save_parsed_data(data: dict, user_dir: str) -> None:\n",
    "    \"\"\"Save structured profile data\"\"\"\n",
    "    save_path = Path(user_dir) / \"profile_data.json\"\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    print(f\"üìÑ Profile data saved to {save_path}\")\n",
    "\n",
    "def display_profile_summary(user_dir: str) -> None:\n",
    "    \"\"\"Display formatted profile summary\"\"\"\n",
    "    data_file = Path(user_dir) / \"profile_data.json\"\n",
    "    if not data_file.exists():\n",
    "        print(\"‚ÑπÔ∏è No profile data available\")\n",
    "        return\n",
    "        \n",
    "    with open(data_file) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(\"\\nüåü Professional Summary:\")\n",
    "    print(f\"Name: {data.get('full_name', 'N/A')}\")\n",
    "    print(f\"Contact: {data.get('contact_email', 'N/A')} | {data.get('phone', 'N/A')}\")\n",
    "    print(f\"\\nüè´ Education ({len(data['education'])} entries)\")\n",
    "    print(f\"\\nüíº Experience ({len(data['experience'])} positions)\")\n",
    "    print(f\"\\nüõ†Ô∏è Technical Skills ({len(data['technical_skills'])} listed)\")\n",
    "\n",
    "\n",
    "# ================== Main Execution Flow ==================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bbc6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_llm(existing: dict, new: dict) -> dict:\n",
    "    \"\"\"Use LLM to intelligently merge two structured profile dicts.\"\"\"\n",
    "    if not existing:\n",
    "        return new\n",
    "    if not new:\n",
    "        return existing\n",
    "\n",
    "    try:\n",
    "        prompt_text = f\"\"\"\n",
    "You are a helpful assistant tasked with merging two structured professional profiles extracted from CVs. \n",
    "Your goal is to intelligently combine the data from both profiles, avoiding redundancy, preserving the most complete and informative entries, and resolving conflicts sensibly.\n",
    "\n",
    "Act as an expert career analyst with deep cross-industry knowledge (tech, healthcare, finance, engineering). \n",
    "You must identify transferable skills, merge overlapping entries, and preserve all unique information, especially for certifications.\n",
    "\n",
    "Please extract and return the following fields in raw JSON format **only**, without preamble or commentary.\n",
    "\n",
    "---\n",
    "**Fields to Extract:**\n",
    "- full_name\n",
    "- contact_email\n",
    "- phone\n",
    "- summary\n",
    "- linkedin\n",
    "- github\n",
    "- education (list)\n",
    "- experience (list)\n",
    "- technical_skills (list)\n",
    "- soft_skills (list, optional)\n",
    "- certifications (list)\n",
    "- projects (list)\n",
    "- languages (optional)\n",
    "YOU CAN ADD AND SUBTRACT FIELDS ACCORDING TO PROVIDED CV AND INDUSTRY\n",
    "---\n",
    "\n",
    "**Guidelines for Merging and Extraction:**\n",
    "\n",
    "1. **Core Info:**\n",
    "   - Extract full legal name from the header or contact block.\n",
    "   - Emails must be valid (e.g., name@domain.com).\n",
    "   - Phone numbers must be in international format (+XXX...).\n",
    "   - Include LinkedIn and GitHub links if found.\n",
    "\n",
    "2. **Education:**\n",
    "   - List all degrees and specializations.\n",
    "   - Include institution name, degree, field, start and end date (MM/YYYY).\n",
    "   - Highlight research projects or thesis titles if available.\n",
    "   - Avoid duplication; if same degree exists with more details, keep the more complete version.\n",
    "\n",
    "3. **Experience:**\n",
    "   - Distinguish jobs, internships, freelance, and volunteering.\n",
    "   - Include job title, company, duration, technologies used, and quantifiable outcomes.\n",
    "   - Keep the most recent or complete version of similar roles.\n",
    "   - Use consistent date format (MM/YYYY).\n",
    "\n",
    "4. **Skills:**\n",
    "   - Group skills into:\n",
    "     ‚Ä¢ Technical Skills (tools, platforms, libraries)\n",
    "     ‚Ä¢ Methodologies (Agile, Scrum, Six Sigma)\n",
    "     ‚Ä¢ Domain Knowledge (e.g., GDPR, HIPAA)\n",
    "   - Include experience levels if stated (e.g., Expert, Intermediate).\n",
    "\n",
    "5. **Certifications (‚úÖ Important):**\n",
    "   - Extract each certification with full name, issuing organization, and date (if available).\n",
    "   - Only merge certifications if the **exact full name and issuer match**.\n",
    "   - If titles are slightly different or have extra info (e.g., \"AWS Certified Developer ‚Äì Associate\" vs \"AWS Developer Cert\"), treat them as separate and preserve both.\n",
    "    \n",
    "6. **Projects:**\n",
    "   - Include title, description, technologies used, role (if specified), and duration.\n",
    "   - Projects may come from personal work, hackathons, university, or freelance.\n",
    "   - Merge only if titles and descriptions are identical or nearly identical.\n",
    "   - Preserve all distinct projects ‚Äî no limit.\n",
    "7. **Languages (if any):**\n",
    "   - Include spoken languages and proficiency if listed.\n",
    "\n",
    "8. **General Rules:**\n",
    "   - Avoid redundancy and merge smartly.\n",
    "   - Prioritize clarity, structure, and richness of information.\n",
    "   - Do not add placeholder or fabricated data.\n",
    "   - Output should be a valid JSON object.\n",
    "   \n",
    "\n",
    "---\n",
    "\n",
    "**Input Profiles:**\n",
    "\n",
    "Profile A (existing):\n",
    "{json.dumps(existing, indent=2)}\n",
    "\n",
    "Profile B (newly parsed):\n",
    "{json.dumps(new, indent=2)}\n",
    "\n",
    "Return ONLY the merged profile in raw JSON format.\n",
    "Do NOT include explanations or commentary. Just output the final merged JSON.\n",
    "\"\"\"\n",
    "    #     response = llm.invoke(prompt_text)\n",
    "    #     return json.loads(response.content.strip())\n",
    "    # except Exception as e:\n",
    "    #     print(f\"‚ö†Ô∏è LLM merge failed: {e}\")\n",
    "    #     return {**existing, **new}  # fallback: simple merge\n",
    "        response = llm.invoke(prompt_text)\n",
    "        raw_output = response.content.strip()\n",
    "\n",
    "        # üìå Safely extract the JSON part from the output\n",
    "        json_start = raw_output.find('{')\n",
    "        json_end = raw_output.rfind('}')\n",
    "        if json_start == -1 or json_end == -1:\n",
    "            raise ValueError(\"No JSON object found in LLM output\")\n",
    "\n",
    "        clean_json = raw_output[json_start:json_end+1]\n",
    "        return json.loads(clean_json)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è LLM merge failed: {e}\")\n",
    "        print(f\"‚ö†Ô∏è Raw LLM output:\\n{response.content if 'response' in locals() else 'No response'}\")\n",
    "        return {**existing, **new}  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebd4115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_cv(user_dir: str) -> None:\n",
    "    \"\"\"Enhanced CV management system\"\"\"\n",
    "    while True:\n",
    "        action = input(\"\\nChoose: [U]pload new, [D]elete, [V]iew, [E]xit: \").strip().lower()\n",
    "        \n",
    "        # if action == \"u\":\n",
    "        #     text = upload_cv(user_dir)\n",
    "        #     parsed = parse_cv(text)\n",
    "        #     save_parsed_data(parsed, user_dir)\n",
    "        if action == \"u\":\n",
    "            text = upload_cv(user_dir)\n",
    "            new_parsed = parse_cv(text)\n",
    "\n",
    "            # Load existing data if it exists\n",
    "            existing_file = Path(user_dir) / \"profile_data.json\"\n",
    "            if existing_file.exists():\n",
    "                with open(existing_file) as f:\n",
    "                    existing_parsed = json.load(f)\n",
    "                merged_data = merge_with_llm(existing_parsed, new_parsed)\n",
    "                print(\"üîÑ Merged new CV with existing profile using LLM.\")\n",
    "            else:\n",
    "                merged_data = new_parsed\n",
    "                print(\"üÜï No existing profile found. Saving new data.\")\n",
    "\n",
    "            save_parsed_data(merged_data, user_dir)\n",
    "\n",
    "        elif action == \"d\":\n",
    "            confirm = input(\"‚ö†Ô∏è Delete ALL profile data? (y/n): \").lower()\n",
    "            if confirm == \"y\":\n",
    "                for item in Path(user_dir).glob(\"*\"):\n",
    "                    item.unlink()\n",
    "                print(\"üóëÔ∏è Profile data deleted\")\n",
    "        elif action == \"v\":\n",
    "            display_profile_summary(user_dir)\n",
    "        elif action == \"e\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid option\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcec5f",
   "metadata": {},
   "source": [
    "# ================== Main Execution Flow =================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95bce232-5a59-4119-9175-c8680e8ec31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Existing profile found\n",
      "‚úÖ CV saved: cv_storage\\meers_gmail.com\\SHAHMEER_KAMRAN_Resume.pdf\n",
      "üîÑ Merged new CV with existing profile using LLM.\n",
      "üìÑ Profile data saved to cv_storage\\meers_gmail.com\\profile_data.json\n",
      "\n",
      "üåü Professional Summary:\n",
      "Name: Shahmeer Gull\n",
      "Contact: shahmeergull20@gmail.com | +92-309-0654885\n",
      "\n",
      "üè´ Education (1 entries)\n",
      "\n",
      "üíº Experience (8 positions)\n",
      "\n",
      "üõ†Ô∏è Technical Skills (18 listed)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def run_cv_pipeline() -> None:\n",
    "    \"\"\"Main execution flow\"\"\"\n",
    "    email, user_dir = get_user_email()\n",
    "    \n",
    "    if not any(Path(user_dir).iterdir()):\n",
    "        print(\"üì• Initial profile setup\")\n",
    "        cv_text = upload_cv(user_dir)\n",
    "        parsed_data = parse_cv(cv_text)\n",
    "        save_parsed_data(parsed_data, user_dir)\n",
    "    else:\n",
    "        manage_cv(user_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_cv_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f967b",
   "metadata": {},
   "source": [
    "### ADD MULTIPLE CV OUTPUT TO ONE PROFILE\n",
    "### MAKE SURE WORD IS BEING READ (USE LANG CHAIN DEFAULT) \n",
    "### MAYBE INTIGERATE CHROMA DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f467537-0964-4bcd-a863-c850cfcaa6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32765fa-2ee1-4bcf-864e-901f77b102ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f6857-0a9d-4bce-970a-b3b0a0e9d248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78974215-839e-4039-ba25-0b32ed0527bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e2d97-5d5d-439d-bd02-04279951b51b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
